{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler,OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing\n",
    "\n",
    "* Create mfcc and genre table from the `features.csv` and `tracks.csv` data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv('tracks.csv', header=1)\n",
    "tracks = tracks.rename(columns={\"Unnamed: 0\": \"track_id\"})\n",
    "tracks = tracks.drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracks.dropna(subset=[\"genre_top\"])"
   ]
  },
  {
   "source": [
    "metadata = metadata.drop([0,1,2]).rename(columns={\"feature\":\"track_id\"})"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_merged_df(m,t):\n",
    "    allmfccs = [\"track_id\"]\n",
    "    mfccdict = {\"track_id\":\"int32\"}\n",
    "    for i in range(1,140):\n",
    "        x = \"mfcc.\"+str(i)\n",
    "        allmfccs.append(x)\n",
    "        mfccdict[x] = \"float\"\n",
    "    tcolumns = [\"track_id\",\"genre_top\"]\n",
    "    tracks = t.astype({\"track_id\":\"int32\"})\n",
    "    meta = m.astype(mfccdict)\n",
    "    tracks = tracks[tcolumns] #data frame with track_ids and genres\n",
    "    meta = meta[allmfccs] # data frame with mfcc and track_ids\n",
    "    merged_df = pd.merge(meta,tracks,on=\"track_id\")\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       track_id    mfcc.1    mfcc.2    mfcc.3    mfcc.4    mfcc.5    mfcc.6  \\\n",
       "0             2  1.541901  0.000816  0.330728  0.118731 -0.342687 -0.259252   \n",
       "1             3  1.399977  0.112535 -0.211170  0.032953 -0.023489  0.150404   \n",
       "2             5  2.415293  0.440233 -0.782131 -0.771069 -0.724216  0.090260   \n",
       "3            10  1.161854  2.095651  1.372743 -0.203574 -0.345354 -0.529139   \n",
       "4           134  0.840775 -0.171289 -0.265671 -0.279361  0.190866 -0.192000   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49593    155315  0.511910  2.573727 -0.444272  0.689142 -0.445705  0.122356   \n",
       "49594    155316  5.361988  3.186483  0.510951 -0.143080  0.342237  0.771449   \n",
       "49595    155317  1.752112  0.442188 -0.380960 -0.739809 -0.023362  0.264786   \n",
       "49596    155318 -0.129386  0.662489  1.025676  0.170532  1.827692 -0.189439   \n",
       "49597    155319  3.716359  2.881116  3.273014  0.707058  1.951918 -0.151555   \n",
       "\n",
       "         mfcc.7    mfcc.8    mfcc.9  ...   mfcc.131  mfcc.132  mfcc.133  \\\n",
       "0      0.146735  0.410656 -0.162872  ...   8.601942  9.284250  9.245516   \n",
       "1      0.046454  0.033484 -0.064596  ...  10.026867  6.978541  7.650417   \n",
       "2      0.152119  0.261731 -0.608905  ...   9.581952  8.895723  8.141456   \n",
       "3      0.561974  0.281350 -0.150672  ...   7.985110  7.075400  6.972649   \n",
       "4      0.422766  0.044087 -0.003510  ...   9.696905  8.477474  7.413949   \n",
       "...         ...       ...       ...  ...        ...       ...       ...   \n",
       "49593 -0.051783  0.124393  1.357606  ...   8.129650  7.889639  6.893649   \n",
       "49594 -0.184232  0.143237  0.009016  ...   6.629143  5.860062  6.230947   \n",
       "49595  0.072084  0.295485  0.535544  ...   6.955739  6.662989  6.478699   \n",
       "49596  1.141878  0.022045  0.175235  ...   6.943147  6.522048  6.780707   \n",
       "49597  0.230036 -0.327132  1.182421  ...   5.971618  6.355647  5.602213   \n",
       "\n",
       "       mfcc.134  mfcc.135  mfcc.136  mfcc.137  mfcc.138  mfcc.139  genre_top  \n",
       "0      8.520863  8.560472  7.651871  7.246555  7.077188  7.391859    Hip-Hop  \n",
       "1      9.600357  7.222888  8.398293  7.285423  7.417791  8.777440    Hip-Hop  \n",
       "2      8.201844  7.780963  7.132692  7.539753  8.452527  7.334442    Hip-Hop  \n",
       "3      7.071393  7.270959  7.051070  6.928591  6.430473  6.186294        Pop  \n",
       "4      7.518894  6.755280  6.344675  6.761541  7.134986  6.803034    Hip-Hop  \n",
       "...         ...       ...       ...       ...       ...       ...        ...  \n",
       "49593  6.792994  7.019863  6.894421  8.094346  6.055836  6.355721       Rock  \n",
       "49594  5.923375  5.586200  5.516872  5.755764  5.105072  5.019556       Rock  \n",
       "49595  6.019901  5.757353  5.280114  5.674062  5.541949  5.266131       Rock  \n",
       "49596  6.311563  5.789986  5.466107  5.607614  5.685448  5.449005       Rock  \n",
       "49597  5.887583  5.110033  5.407447  5.317993  5.187994  5.260817       Rock  \n",
       "\n",
       "[49598 rows x 141 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>mfcc.1</th>\n      <th>mfcc.2</th>\n      <th>mfcc.3</th>\n      <th>mfcc.4</th>\n      <th>mfcc.5</th>\n      <th>mfcc.6</th>\n      <th>mfcc.7</th>\n      <th>mfcc.8</th>\n      <th>mfcc.9</th>\n      <th>...</th>\n      <th>mfcc.131</th>\n      <th>mfcc.132</th>\n      <th>mfcc.133</th>\n      <th>mfcc.134</th>\n      <th>mfcc.135</th>\n      <th>mfcc.136</th>\n      <th>mfcc.137</th>\n      <th>mfcc.138</th>\n      <th>mfcc.139</th>\n      <th>genre_top</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1.541901</td>\n      <td>0.000816</td>\n      <td>0.330728</td>\n      <td>0.118731</td>\n      <td>-0.342687</td>\n      <td>-0.259252</td>\n      <td>0.146735</td>\n      <td>0.410656</td>\n      <td>-0.162872</td>\n      <td>...</td>\n      <td>8.601942</td>\n      <td>9.284250</td>\n      <td>9.245516</td>\n      <td>8.520863</td>\n      <td>8.560472</td>\n      <td>7.651871</td>\n      <td>7.246555</td>\n      <td>7.077188</td>\n      <td>7.391859</td>\n      <td>Hip-Hop</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1.399977</td>\n      <td>0.112535</td>\n      <td>-0.211170</td>\n      <td>0.032953</td>\n      <td>-0.023489</td>\n      <td>0.150404</td>\n      <td>0.046454</td>\n      <td>0.033484</td>\n      <td>-0.064596</td>\n      <td>...</td>\n      <td>10.026867</td>\n      <td>6.978541</td>\n      <td>7.650417</td>\n      <td>9.600357</td>\n      <td>7.222888</td>\n      <td>8.398293</td>\n      <td>7.285423</td>\n      <td>7.417791</td>\n      <td>8.777440</td>\n      <td>Hip-Hop</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>2.415293</td>\n      <td>0.440233</td>\n      <td>-0.782131</td>\n      <td>-0.771069</td>\n      <td>-0.724216</td>\n      <td>0.090260</td>\n      <td>0.152119</td>\n      <td>0.261731</td>\n      <td>-0.608905</td>\n      <td>...</td>\n      <td>9.581952</td>\n      <td>8.895723</td>\n      <td>8.141456</td>\n      <td>8.201844</td>\n      <td>7.780963</td>\n      <td>7.132692</td>\n      <td>7.539753</td>\n      <td>8.452527</td>\n      <td>7.334442</td>\n      <td>Hip-Hop</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>1.161854</td>\n      <td>2.095651</td>\n      <td>1.372743</td>\n      <td>-0.203574</td>\n      <td>-0.345354</td>\n      <td>-0.529139</td>\n      <td>0.561974</td>\n      <td>0.281350</td>\n      <td>-0.150672</td>\n      <td>...</td>\n      <td>7.985110</td>\n      <td>7.075400</td>\n      <td>6.972649</td>\n      <td>7.071393</td>\n      <td>7.270959</td>\n      <td>7.051070</td>\n      <td>6.928591</td>\n      <td>6.430473</td>\n      <td>6.186294</td>\n      <td>Pop</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>134</td>\n      <td>0.840775</td>\n      <td>-0.171289</td>\n      <td>-0.265671</td>\n      <td>-0.279361</td>\n      <td>0.190866</td>\n      <td>-0.192000</td>\n      <td>0.422766</td>\n      <td>0.044087</td>\n      <td>-0.003510</td>\n      <td>...</td>\n      <td>9.696905</td>\n      <td>8.477474</td>\n      <td>7.413949</td>\n      <td>7.518894</td>\n      <td>6.755280</td>\n      <td>6.344675</td>\n      <td>6.761541</td>\n      <td>7.134986</td>\n      <td>6.803034</td>\n      <td>Hip-Hop</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49593</th>\n      <td>155315</td>\n      <td>0.511910</td>\n      <td>2.573727</td>\n      <td>-0.444272</td>\n      <td>0.689142</td>\n      <td>-0.445705</td>\n      <td>0.122356</td>\n      <td>-0.051783</td>\n      <td>0.124393</td>\n      <td>1.357606</td>\n      <td>...</td>\n      <td>8.129650</td>\n      <td>7.889639</td>\n      <td>6.893649</td>\n      <td>6.792994</td>\n      <td>7.019863</td>\n      <td>6.894421</td>\n      <td>8.094346</td>\n      <td>6.055836</td>\n      <td>6.355721</td>\n      <td>Rock</td>\n    </tr>\n    <tr>\n      <th>49594</th>\n      <td>155316</td>\n      <td>5.361988</td>\n      <td>3.186483</td>\n      <td>0.510951</td>\n      <td>-0.143080</td>\n      <td>0.342237</td>\n      <td>0.771449</td>\n      <td>-0.184232</td>\n      <td>0.143237</td>\n      <td>0.009016</td>\n      <td>...</td>\n      <td>6.629143</td>\n      <td>5.860062</td>\n      <td>6.230947</td>\n      <td>5.923375</td>\n      <td>5.586200</td>\n      <td>5.516872</td>\n      <td>5.755764</td>\n      <td>5.105072</td>\n      <td>5.019556</td>\n      <td>Rock</td>\n    </tr>\n    <tr>\n      <th>49595</th>\n      <td>155317</td>\n      <td>1.752112</td>\n      <td>0.442188</td>\n      <td>-0.380960</td>\n      <td>-0.739809</td>\n      <td>-0.023362</td>\n      <td>0.264786</td>\n      <td>0.072084</td>\n      <td>0.295485</td>\n      <td>0.535544</td>\n      <td>...</td>\n      <td>6.955739</td>\n      <td>6.662989</td>\n      <td>6.478699</td>\n      <td>6.019901</td>\n      <td>5.757353</td>\n      <td>5.280114</td>\n      <td>5.674062</td>\n      <td>5.541949</td>\n      <td>5.266131</td>\n      <td>Rock</td>\n    </tr>\n    <tr>\n      <th>49596</th>\n      <td>155318</td>\n      <td>-0.129386</td>\n      <td>0.662489</td>\n      <td>1.025676</td>\n      <td>0.170532</td>\n      <td>1.827692</td>\n      <td>-0.189439</td>\n      <td>1.141878</td>\n      <td>0.022045</td>\n      <td>0.175235</td>\n      <td>...</td>\n      <td>6.943147</td>\n      <td>6.522048</td>\n      <td>6.780707</td>\n      <td>6.311563</td>\n      <td>5.789986</td>\n      <td>5.466107</td>\n      <td>5.607614</td>\n      <td>5.685448</td>\n      <td>5.449005</td>\n      <td>Rock</td>\n    </tr>\n    <tr>\n      <th>49597</th>\n      <td>155319</td>\n      <td>3.716359</td>\n      <td>2.881116</td>\n      <td>3.273014</td>\n      <td>0.707058</td>\n      <td>1.951918</td>\n      <td>-0.151555</td>\n      <td>0.230036</td>\n      <td>-0.327132</td>\n      <td>1.182421</td>\n      <td>...</td>\n      <td>5.971618</td>\n      <td>6.355647</td>\n      <td>5.602213</td>\n      <td>5.887583</td>\n      <td>5.110033</td>\n      <td>5.407447</td>\n      <td>5.317993</td>\n      <td>5.187994</td>\n      <td>5.260817</td>\n      <td>Rock</td>\n    </tr>\n  </tbody>\n</table>\n<p>49598 rows × 141 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "track_mfcc_df = get_merged_df(metadata,tracks)\n",
    "track_mfcc_df"
   ]
  },
  {
   "source": [
    "## Encode the labels and Creating X and Y data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = track_mfcc_df.iloc[:,-1]\n",
    "encoder = OneHotEncoder()\n",
    "Y = encoder.fit_transform(np.array(genre_list).reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(track_mfcc_df.iloc[:,1:-1], dtype = float))"
   ]
  },
  {
   "source": [
    "## Create Testing and Training Sets "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((39678, 139), (39678, 16))"
      ]
     },
     "metadata": {},
     "execution_count": 179
    }
   ],
   "source": [
    "X_new = X_train\n",
    "Y_new = Y_train\n",
    "X_new.shape,Y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_new = np.expand_dims(X_train, axis=1)\n",
    "#Y_new = np.expand_dims(np.expand_dims(Y_train, axis=1),axis=2)\n",
    "#X_new.shape,Y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(39678, 9920, (39678, 1, 139), (39678, 1, 16), array([0., 1.]))"
      ]
     },
     "metadata": {},
     "execution_count": 181
    }
   ],
   "source": [
    "X_train = np.expand_dims(X_train, axis =1)\n",
    "X_test  = np.expand_dims(X_test,  axis =1)\n",
    "Y_train = np.expand_dims(Y_train,axis=1)\n",
    "Y_test  = np.expand_dims(Y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(39678, 9920, (39678, 1, 139), (39678, 1, 16), (9920, 1, 139))"
      ]
     },
     "metadata": {},
     "execution_count": 185
    }
   ],
   "source": [
    "len(X_train),len(X_test),X_train.shape,Y_train.shape,X_test.shape #Total of 15 genres "
   ]
  },
  {
   "source": [
    "# Create LSTM network "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(16, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/25\n",
      "155/155 [==============================] - 2s 7ms/step - loss: 1.9977 - accuracy: 0.4403 - val_loss: 1.3672 - val_accuracy: 0.5744\n",
      "Epoch 2/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 1.3161 - accuracy: 0.5863 - val_loss: 1.2659 - val_accuracy: 0.6027\n",
      "Epoch 3/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 1.2122 - accuracy: 0.6102 - val_loss: 1.2262 - val_accuracy: 0.6108\n",
      "Epoch 4/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 1.1630 - accuracy: 0.6221 - val_loss: 1.1990 - val_accuracy: 0.6157\n",
      "Epoch 5/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 1.1202 - accuracy: 0.6371 - val_loss: 1.1827 - val_accuracy: 0.6241\n",
      "Epoch 6/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 1.0981 - accuracy: 0.6410 - val_loss: 1.1726 - val_accuracy: 0.6255\n",
      "Epoch 7/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 1.0498 - accuracy: 0.6555 - val_loss: 1.1647 - val_accuracy: 0.6264\n",
      "Epoch 8/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 1.0326 - accuracy: 0.6630 - val_loss: 1.1597 - val_accuracy: 0.6267\n",
      "Epoch 9/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 1.0173 - accuracy: 0.6685 - val_loss: 1.1558 - val_accuracy: 0.6291\n",
      "Epoch 10/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.9861 - accuracy: 0.6791 - val_loss: 1.1523 - val_accuracy: 0.6284\n",
      "Epoch 11/25\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.9635 - accuracy: 0.6846 - val_loss: 1.1527 - val_accuracy: 0.6290\n",
      "Epoch 12/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.9369 - accuracy: 0.6948 - val_loss: 1.1500 - val_accuracy: 0.6334\n",
      "Epoch 13/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.9214 - accuracy: 0.7006 - val_loss: 1.1533 - val_accuracy: 0.6303\n",
      "Epoch 14/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.9053 - accuracy: 0.7040 - val_loss: 1.1556 - val_accuracy: 0.6304\n",
      "Epoch 15/25\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.8804 - accuracy: 0.7140 - val_loss: 1.1599 - val_accuracy: 0.6309\n",
      "Epoch 16/25\n",
      "155/155 [==============================] - 1s 4ms/step - loss: 0.8625 - accuracy: 0.7218 - val_loss: 1.1636 - val_accuracy: 0.6271\n",
      "Epoch 17/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.8447 - accuracy: 0.7233 - val_loss: 1.1655 - val_accuracy: 0.6307\n",
      "Epoch 18/25\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.8318 - accuracy: 0.7315 - val_loss: 1.1732 - val_accuracy: 0.6268\n",
      "Epoch 19/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.8073 - accuracy: 0.7397 - val_loss: 1.1781 - val_accuracy: 0.6281\n",
      "Epoch 20/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.8009 - accuracy: 0.7409 - val_loss: 1.1814 - val_accuracy: 0.6292\n",
      "Epoch 21/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.7722 - accuracy: 0.7517 - val_loss: 1.1867 - val_accuracy: 0.6285\n",
      "Epoch 22/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.7648 - accuracy: 0.7563 - val_loss: 1.1929 - val_accuracy: 0.6226\n",
      "Epoch 23/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.7498 - accuracy: 0.7617 - val_loss: 1.2034 - val_accuracy: 0.6240\n",
      "Epoch 24/25\n",
      "155/155 [==============================] - 1s 5ms/step - loss: 0.7398 - accuracy: 0.7652 - val_loss: 1.2111 - val_accuracy: 0.6243\n",
      "Epoch 25/25\n",
      "155/155 [==============================] - 1s 6ms/step - loss: 0.7244 - accuracy: 0.7715 - val_loss: 1.2157 - val_accuracy: 0.6226\n"
     ]
    }
   ],
   "source": [
    "history = lstm_model.fit(X_train,\n",
    "                         Y_train,\n",
    "                         epochs=25,\n",
    "                         batch_size=256,\n",
    "                         validation_data=(X_test,Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}